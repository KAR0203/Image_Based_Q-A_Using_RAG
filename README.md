# ğŸ§  Image-Based Q&A Using RAG

This project enables users to ask questions about the contents of an image using a **Retrieval-Augmented Generation (RAG)** approach. It combines vision and language models to understand image context and answer questions accordingly.

---

## ğŸ“Œ Features

- ğŸ“¸ Upload an image (JPG/PNG)
- ğŸ§¾ Generate a descriptive caption using **BLIP-2**
- â“ Ask questions about the image
- ğŸ¤– Use **Sentence Transformers** to match your question to the context
- ğŸ§  Generate answers using a **Large Language Model (LLM)**

---

## ğŸš€ How It Works

1. **Upload Image**: The image is processed to extract a caption.
2. **Generate Context**: The image caption is passed to a sentence transformer.
3. **Ask Questions**: User can ask questions about the image content.
4. **Answer Generated**: A large language model answers the question based on the caption.

---

## ğŸ“‚ Files Included

- `Image_based_Q&A (2).ipynb` â€“ Main Jupyter Notebook with code.
- `README.md` â€“ Project documentation.

---

## ğŸ“¦ Requirements

Install dependencies with:

```bash
pip install transformers sentence-transformers torch streamlit
